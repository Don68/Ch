{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Inlämning_laboration_3_regression_klassificering (original).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Don68/Ch/blob/master/Inl%C3%A4mning_laboration_3_regression_klassificering_(original).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqnJfMWWV4sS"
      },
      "source": [
        "# Laboration 3 Regression och klassificiering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8KJTFrdV4sT"
      },
      "source": [
        "## Laboration 3 - del 1 Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FpdjAb9V4sT"
      },
      "source": [
        "I första delen av laboration 3 ska ni  applicera linjär regression och polynomisk regression på två olika dataset samt jämföra dessa två modeller på två olika dataset.  \n",
        "\n",
        "Polynomisk regression är alltså basis function regression med x = 𝜙(x upphöjt med i), se föreläsning 5\n",
        "\n",
        "Laborationen är inspirerad av Nhan Tran i Towards Data Science. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPceJ2WbV4sU"
      },
      "source": [
        "### Förberedelser och uppsättning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG_eQxxEV4sV"
      },
      "source": [
        "#importera nödvändiga bibliotek\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjKrTMcxV4sY"
      },
      "source": [
        "När nödvändiga bibliotek och det dataset vi ska använda är importerat är det dags att göra oss familijär med den data vi ska analysera. Ett bra sätt att göra det är att visualisering. Men allra först vill vi titta på de första raderna i vår data. Använd Python för att hämta dessa i kodblocket nedan. Vi vill också räkna antalet rader totalt i vårt dataset och skriva ut det, samt göra några beräkningar på data såsom medel och medianvärde på löner i respektive position."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJOY40E_V4sY"
      },
      "source": [
        "**F1** Importera de två dataset vi ska använda position_salaries och salary_data\n",
        "\n",
        "**F2** Titta på de två dataset vi har, hur ser de ut (storlek, datatyper etc)? \n",
        "\n",
        "**F3** Vilka kolumner innehåller numerisk data och vilka innehåller kategorisk?\n",
        "\n",
        "**F3** Vad är medel och median för löner baserat på antal år och efter position? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRL6r04kV4sZ"
      },
      "source": [
        "**F5** \n",
        "\n",
        ">a. Behöver vi göra någon tvättning av data för att kunna använda dessa dataset för att träna våra regressionsmodeller? \n",
        ">\n",
        ">b. Om **ja**, utför lämpliga pre-processing aktiviteter på båda dessa dataset.\n",
        ">\n",
        ">c. Om **nej**, varför behövs inte det?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXf_2zEkV4sZ"
      },
      "source": [
        "För att kunna skapa en modell behöver vi ha oberoende variabler (x) och beroende variabler (y), för enkel linjär regression har vi bara ett x och ett y. \n",
        "\n",
        "**F6**\n",
        "\n",
        ">a. Vilka variabler för x och y är lämpliga i våra dataset? Varför?\n",
        ">\n",
        ">b.Skapa variablerna x och y för respektive dataset som X_pos, y_pos och X_sal, y_sal.\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgnRj5Y8V4sa"
      },
      "source": [
        "För att skapa både tränings- och testdata bör vi dela vårt tillgänliga data i ett träningsset och ett testset.  \n",
        "\n",
        "**F7** Koda en instruktion som delar dina två datafiler så att ca 30% blir testdata och 70% blir träningsdata. Gör alltså detta för båda era dataset. \n",
        "\n",
        "HINT! Importera följande modul i scikit_learn: `from sklearn.model_selection import train_test_split`\n",
        "\n",
        "**F8** Givet den data vi har, kan vi träna och testa en modell ordentligt? Varför/varför inte?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUkIBPmIV4sa"
      },
      "source": [
        "### Modellering och kvalitetsgranskning\n",
        "\n",
        "Nu är det dags att ta en titt på en linjär regression approximering av vårt data, alltså att visualisera hur en rät linje kan anpassas till vårt data. För detta använder vi återigen biblioteket sklearn som har metoder för linjär regression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TqnNRbcV4sb"
      },
      "source": [
        "**F9** Träna\n",
        "\n",
        ">a. Approximera en rät linje för vart och ett av våra dataset. HINT! `from sklearn.linear_model import LinearRegression``\n",
        ">\n",
        ">b. Vilket data ska vi använda för att träna våra modeller?\n",
        ">\n",
        "\n",
        "**F10** Prediktera\n",
        ">\n",
        ">a. Vilka data ska vi göra vår prediktion på?\n",
        ">\n",
        ">b. Vilken variabel ska vi prediktera?\n",
        ">\n",
        ">c. Utför prediktionen\n",
        "\n",
        "**F11** Visualisera resultaten (HINT! Plotta datapunkterna med scatterplot och rita ut den räta linjen som du predikterat för varje dataset i samma graf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLhYa5pgV4sb"
      },
      "source": [
        "Dags att testa hur väl vår modell tränades. \n",
        "\n",
        "**F12** \n",
        "\n",
        ">a. Utför linär regression på våra två testdataset, visualisera resultatet.\n",
        ">\n",
        ">b. Varför ser det ut som det gör? Är det något som är oväntat? Vad och varför?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOxtsKp8V4sc"
      },
      "source": [
        "Förutom att visualisera vårt resultat för att se hur väl vår valda modell passar vårt problem kan vi också använda beräkningar för att se hur bra vår modell är. Ett av de absolut enklaste sätten är att jämföra med medelvärdet för varje prediktkerat värde, modellen bör åtminstonde vara bättre än detta värde. \n",
        "\n",
        "**F13** Hur förhåller sig våra resultat för vårt testdata i förhållande till medelvärdet för de predikterade värdena? Bättre eller sämre?\n",
        "\n",
        "Bättre sätt att beräkna \"fit\" för linjär regression är R^2 score och MSE, RMSE (Root mean square error). Dessa kan vi räkna ut direkt med hjälp av inbyggda funktioner. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIsz-tUEV4sd"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from math import sqrt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEPYA8XnV4sf"
      },
      "source": [
        "**F14** Beräkna kvalitetsvärden för träningsdata av båda våra dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIM3dU12V4sg"
      },
      "source": [
        "**F15** Ok, hur ser de ut?\n",
        "\n",
        ">a. Är en rät linje en bra approximation för våra två dataset? Varför?\n",
        ">\n",
        ">b. Vad säger våra kvalitetsvärden? \n",
        ">\n",
        ">Vilket sätt är enklast för att veta hur \"bra\" våra modeller är? Visualisering eller beräkning av värden?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIlQ_StzV4sh"
      },
      "source": [
        "För ett av våra dataset verkar linjäritet inte riktigt finnas mellan vår beroende och oberoende variabel. För detta data behöver vi därför testa med något annat för att få en bra modell som vi kan använda för att prediktera. \n",
        "\n",
        "**F16** Vi testar att istället anpassa en polynomiskt beräknad linje till vårt ena dataset. HINT! `from sklearn.preprocessing import PolynomialFeatures` Träna och testa alltså en polynomisk regressionsmodell och visualiera resultaten för olika grader av polynom. Besvara också följande frågor.\n",
        "\n",
        ">a. Vilket dataset behöver vi ha en annan modell för? \n",
        ">\n",
        ">b. Varför är polynom möjligtvis lämpligt?\n",
        ">\n",
        ">c. Testa med olika grader, vilken grad är bäst lämpad? \n",
        ">\n",
        ">d. Vilken grad motsvarar vår ursprunliga linje?\n",
        ">\n",
        ">e. Vad motsvarar 0?\n",
        ">\n",
        ">f. Hur vet vi när vår modell är övertränad? (overfitted)?\n",
        ">\n",
        ">g. Vid vilken grad på polynom börjar detta inträffa?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tchhAWLBV4sh"
      },
      "source": [
        "**F17** Ok, vad ska vi nu ha detta till? Jo, för att beräkna vad för lön man ska erbjuda sina nyanställda för att de ska tacka ja! \n",
        "\n",
        ">a. Vilken modell skulle du välja och varför? \n",
        ">\n",
        ">b. Vilken data vill du ha för att träna din valda modell?\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7KzY_k5V4si"
      },
      "source": [
        "## Del 2 Klassificering\n",
        "\n",
        "I denna andra del ska ni testa att klassificera ett annat dataset med hjälp av två olika modeller för klassificering, logistiskt regression och desicion trees (som klarar såväl regression som klassificering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1weu2qX7V4si"
      },
      "source": [
        "I nästa del av laboration 3 ska ni träna på klassificering. Vi kommer använda ett dataset som har data om överlevare från Titanic. \n",
        "\n",
        "Den del av laboration som handlar om decision trees är inspirerad av David Johnsson på Uppsala universitet.\n",
        "\n",
        "Det dataset vi ska använda finns i datamappen, precis som vanligt. Några av de bibliotek ni behöver för att komma igång är också importerade. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajkIBgOuV4sj"
      },
      "source": [
        "### Logistisk regression för att bestämma om man överlever eller inte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE2PzAJDV4sj"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "from pandas import Series, DataFrame\n",
        "from pylab import rcParams\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics \n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgaf0I1aV4sm"
      },
      "source": [
        "%matplotlib inline\n",
        "rcParams['figure.figsize'] = 10, 8\n",
        "sb.set_style('whitegrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U1VhdjTV4sp"
      },
      "source": [
        "**F1** Läs in datafilen och gör dig familiär med den. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDZ_OsZDV4sp"
      },
      "source": [
        "### Översikt över några kolumner - fyll i vad varje kolumn står för där information saknas\n",
        "\n",
        "- `survival` - \n",
        "- `pclass` - \n",
        "- `sex` - \n",
        "- `age`- \n",
        "- `sibsp` - # av syskon/äkta hälft ombord \n",
        "- `parch` - # av föräldrar/barn ombord \n",
        "- `ticket` - \n",
        "- `fare` - \n",
        "- `cabin` - \n",
        "- `embarked` - Hamn där man steg ombord (C = Cherbourg, Q = Queenstown, S = Southampton)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15mVA5YoV4sq"
      },
      "source": [
        "**F2** Hur många passagerare fanns på Titanic enligt ert dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9oQ6zffV4sq"
      },
      "source": [
        "### Explorativ dataanalys\n",
        "\n",
        "För att veta vilka data som har betydelse när det handlar om att klassificera huruvida en person lever eller dör behöver vi undersöka vårt dataset med fokus på vilka variabler som påverkar `survival`. Först behöver vi dock städa och förbereda data för analys."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GreuosIGV4sr"
      },
      "source": [
        "**F3** Börja med att undersöka hur många som levde och hur många som dog.\n",
        "\n",
        ">a. Antal som överlevde och antal som dog?\n",
        ">\n",
        ">b. Hur många % överlevde?\n",
        ">\n",
        ">c. Visualisera antal överlevare och antal döda i ett stapeldiagram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpQ0GaRmV4sr"
      },
      "source": [
        "**F4** Städa ert data, hantera nullvärden, kontrollera outliers, typ av variabler (kategoriska, kontinuerliga, numeriska/labels)\n",
        "\n",
        ">\n",
        ">a. Vilka kolumner har nullvärden?\n",
        ">\n",
        ">b. Hur kan dessa hanteras? \n",
        ">\n",
        ">c.Vilken typ av nullvärden har ni (MCAR/MAR/NMAR)?\n",
        ">\n",
        ">d. Vilka risker finns med ert sätt att hantera nullvärden? Varför? \n",
        ">\n",
        ">e.Finns det outliers? Behöver de hanteras?\n",
        ">\n",
        ">f.Vilka variabler är kategoriska och vilka är kontinuerliga?\n",
        ">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek_myBvTV4ss"
      },
      "source": [
        "I följande uppgifter ska ni testa två olika varianter för att ersätta null och jämföra dessa med varandra samt välja den bästa för ert syfte. \n",
        "\n",
        "**F5** Ersätt null med medianåldern\n",
        "**OBS!** Kom ihåg att du måste spara dina ändringar i en ny dataframe, det går inte att ta bort null två gånger ur samma df. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ6dVG73V4ss"
      },
      "source": [
        "# F5: Ersätt ålder med medianåldern\n",
        "titanic_passenger_fill_null_median = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h3kZnMIV4su"
      },
      "source": [
        "**F6** Ersätt null med lämpliga värden baserat på andra variabler i ert dataset.\n",
        "\n",
        ">a. För att beräkna korrelationen mellan olika variabler i ett dataset kan vi använda pandas inbyggda `corr()`. I nedan kodcell kontrolleras samtliga variabler gentemot varandra.\n",
        ">\n",
        ">b. Varför är det 1.00000 i flera rader?\n",
        ">\n",
        ">c. Vilka kolumner har någon korrelation med varandra? \n",
        ">HINT! En rule of thumb kan sägas vara att varaibler är svagt korrelerande om korrelationskoefficienten (r) är mellan 0,2-0,39, medelkorrelerade >mellan 0,4-0,59, och starkt korrelerade mellan 0,6-0,79, över 0,8 är mycket stark korrelation och 1 är helt beroende variabler. \n",
        ">\n",
        ">d.Den starkaste korrelationen finns mellan ålder och klass. Vilken typ av korrelation är det (negativ eller positiv) och hur stark?\n",
        ">\n",
        ">e.I cellen under korrelationsberäkningen görs en visualisering av ålder i relation till klass. Vad säger den?\n",
        ">\n",
        ">f.Ersätt nullvärdena i age baserat på vad du kom fram till i fråga e. \n",
        ">\n",
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TtR1FYJV4sv"
      },
      "source": [
        "#Ersätt med relevant ålder beroende på korrelerad variabel\n",
        "titanic_passengers.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EgIbxNzV4sx"
      },
      "source": [
        "sb.boxplot(x='Pclass', y='Age', data=titanic_data, palette='hls')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFFJVlTdV4sz"
      },
      "source": [
        "titanic_passenger_fill_null_class_median ="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZqFATaZV4s3"
      },
      "source": [
        "**F7** Vilket sätt är att föredra?\n",
        "(HINT! kontrollera de vanliga mätvärdena du får med `.describe()` för ert dataset innan och efter ni ersätter nullvärden, dessa bör vara ungefär samma före som efter ex. median/medel/max/min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0m6h-6oV4s3"
      },
      "source": [
        "**F8** Det finns en till kolumn med nullvärden \n",
        "\n",
        ">a.Vad är lämpligt att göra med den?\n",
        ">\n",
        ">b.Gör det :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pBT26HaV4s4"
      },
      "source": [
        "**F8** Analys av varaibler\n",
        "\n",
        "Nu har vi städat vårt dataset är det dags att förbereda det för analys. \n",
        "\n",
        ">a. Vilka variabler är överhuvudtaget inte intressanta för huruvida man lever eller dör? Kontrollera i vår korrelationsanalys.(OBS! Alla kolumner finns inte med eftersom det inte går att beräkna korrelation på vissa)\n",
        ">\n",
        ">b.När vi använder logistisk regression vill vi inte att de oberoende variablerna ska vara för korrelerade (beroende) av varandra. Det påverkar resultatet negativt. Därför tittar vi igen på vår korrelationsanalys. För att vi ska tycka korrelationen är för stark bör gränsvärdet ligga runt 0,4, ta bort de variabler som har en korrelation starkare än 0,4.\n",
        ">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmarGufQV4s4"
      },
      "source": [
        "**F9** Se till att variablerna går att applicera i vald modell.\n",
        "\n",
        "Eftersom vi ska använda logistisk regression måste alla värden vara numeriska, vi behöver alltså ändra våra kategoriska, icke-numeriska variabler till numeriska. Detta görs lämpligen genom ungefär följande kod: `dataframe_without_kategorial_sex = pd.get_dummies(*namnet på ddataframen*, columns=['Sex'], drop_first=True)`\n",
        "\n",
        ">\n",
        ">a. Varför ersätter vi med 0 och 1 istället för 0,1,2,3?\n",
        ">\n",
        ">b. Ersätt övriga kategoriska kolumner med dummyvariabler. \n",
        ">\n",
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKmPvBogV4s5"
      },
      "source": [
        "#9b: Gör samma sak för övriga kategoriska variabler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgtiuZ3WV4s7"
      },
      "source": [
        "**F10** Skapa modell, träna och testa \n",
        "\n",
        "(OBS! Se till att ni döper era variabler till X-train, X_test,y_train,y_test annars fungerar inte utvärderingskoden)\n",
        "\n",
        ">\n",
        ">a. Starta med att formatera data så att du skapar X och y där y är den beroende variabeln survival och X är samtliga beroende variabler (de som finns kvar i ert dataset)\n",
        ">\n",
        ">b. Dela i träning (80%) och test (20%)\n",
        ">\n",
        ">c. Har vi tillräckligt med data för att kunna träna vår modell eller måste vi ta bort fler kolumner? HINT! en rule of thumb säger minst 50 rader per beroende variabel.\n",
        ">\n",
        ">d.Skapa och träna modell (kod finns för starten)\n",
        ">\n",
        ">e.Testa modell på träningsdata\n",
        ">\n",
        ">f. Prediktera sannolikheten för att en kvinna, ålder 34, med två barn som reser i 2:a klass med sin man överlever? \n",
        ">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GK2Ajl2V4s8"
      },
      "source": [
        "**F11** Utvärdera modell\n",
        "\n",
        "I nedanstående kodblock utvärderas klassificeringsmodellen på några olika sätt. \n",
        "\n",
        ">\n",
        ">a. Vilka sätt att utvärdera en klassificeringsmodell är kodade nedan?\n",
        ">\n",
        ">b. För varje kodblock, kommentera koden så det är förståeligt vad som händer\n",
        ">\n",
        ">c. För varje metod som är kodad, vad visar den för vår klassificerare? \n",
        ">\n",
        ">d. Vad är er bedömning av vår klassificerare (bra/dålig) vad baserar ni detta på och varför?\n",
        ">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txz077OhV4s8"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56OiQhWuV4s-"
      },
      "source": [
        "class_names=[0,1] # name  of classes\n",
        "fig, ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "# create heatmap\n",
        "sb.heatmap(pd.DataFrame(confusion_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OfEFyqMV4tA"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYSOO8lUV4tD"
      },
      "source": [
        "### Desicion trees för att bestämma vilka som överlever\n",
        "\n",
        "Vi ska också testa att använda ett beslutsträd för att bestämma vilka som överlever. Koden för detta är redan given nedan. Dock ska ni besvara några frågor kring beslutsträd och jämföra resultatet mellan de två klassificerarna. \n",
        "\n",
        "**F12** Följande frågor ska besvaras, vissa kan kräva att ni skriver kod. Ni ska också kommentera koden så att det framgår vad som görs.\n",
        "\n",
        ">\n",
        ">a. Vilka oberoende variabler (features) används i beslutsträdet för att avgöra vem som överlever?\n",
        ">\n",
        ">b.Hur många män respektive kvinnor överlever i prediktionen om du testar att prediktera med endast de 10 första raderna som sample (OBS! Kräver kod)\n",
        ">\n",
        ">c. Hur många felaktiga respektive korrekta prediktioner gör beslutsträdet i jämförelse med den logistiska regressionen?\n",
        ">\n",
        ">d. Vilken av algoritmerna är \"bäst? för uppgiften?\n",
        ">\n",
        ">e. Vilka svagheter respektive styrkor har de båda modellerna i jämförelse med varandra?\n",
        ">\n",
        ">f.När du tittar på visualiseringen av beslutsträdet, hur set det ut som algoritmen fungerar, i avseende på hur den väljer väg?\n",
        ">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CgbE0xwV4tE"
      },
      "source": [
        "survived_data = titantic_passengers.survived\n",
        "titantic_passengers = titantic_passengers[['sex_male', 'fare', 'age', 'sibsp']]\n",
        "titantic_passengers.info()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG0dn7rxV4tE"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(titantic_passengers, survived_data, test_size=0.25)\n",
        "print(\"Our training data has {} rows\".format(len(X_train)))\n",
        "print(\"Our test data has {} rows\".format(len(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfyIiCojV4tG"
      },
      "source": [
        "classifier = DecisionTreeClassifier(max_depth=3)\n",
        "classifier.fit(X_train.values, y_train.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RR1SCPdV4tI"
      },
      "source": [
        "y_pred = classifier.predict(X_test.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqXJc3ybV4tK"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test.values, y_pred)\n",
        "confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m4_zIZqV4tM"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9kE9e4jV4tO"
      },
      "source": [
        "tree_plot = Source(tree.export_graphviz(classifier, out_file=None, \n",
        "                            feature_names=X_train.columns, class_names=['Dead', 'Alive'], \n",
        "                            filled=True, rounded=True, special_characters=True))\n",
        "tree_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aQWLZRBV4tR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}